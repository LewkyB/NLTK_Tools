# NLTK_Tools

Got my hands on a lot of plain text books for training ML from bookcorpus and didn't know what all to do with them.

I hadn't experimented much with grep and quickly wore that out on the files. Then, I eventually moved on to NLTK for something more to do.

## Uses

* Tokenize plain text books into words, cleans the words, then you can create frequency distribution plots or word clouds 

## Downloads

Downloads are all very fast. 

* [download for 2gb zip that unpacks to 6gb, about 19000 books](https://the-eye.eu/public/AI/pile_preliminary_components/books1.tar.gz)
* [download the 37gb monster with 197000 books](https://the-eye.eu/public/AI/pile_preliminary_components/books3.tar.gz)
* [links are courtesy of this comment on Github](https://github.com/soskek/bookcorpus/issues/27#issuecomment-716104208)

## Packages

* [NLTK](https://www.nltk.org/)
* [word_cloud](https://github.com/amueller/word_cloud)


## Other resources

https://github.com/NirantK/nlp-python-deep-learning

https://github.com/keon/awesome-nlp#user-content-python